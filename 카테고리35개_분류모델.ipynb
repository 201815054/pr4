{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bdccfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4529521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425ad8c",
   "metadata": {},
   "source": [
    "# 파일 데이터 가져와서 라벨 붙이기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "791f278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a51bed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bitcamp\\\\Project4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 있는 경로로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7ae47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\Project4\\data\\CNBC뉴스분류-20220425T095102Z-001\\CNBC뉴스분류\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\bitcamp\\Project4\\data\\CNBC뉴스분류-20220425T095102Z-001\\CNBC뉴스분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "966d58dd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeled_news_oil_0_100_oil_price.csv.csv',\n",
       " 'labeled_news_oil_100_200_oil_price.csv.csv',\n",
       " 'labeled_news_oil_200_300_oil_price.csv.csv',\n",
       " 'labeled_news_oil_300_400_oil_price.csv.csv',\n",
       " 'labeled_news_oil_400_500_oil_price.csv.csv',\n",
       " 'labeled_news_oil_500_600_oil_price.csv.csv',\n",
       " 'labeled_news_oil_600_700_oil_price.csv.csv',\n",
       " 'labeled_news_oil_700_end_oil_price.csv.csv',\n",
       " 'labeled_news_semiconductor_0_100_semicondutor.csv.csv',\n",
       " 'labeled_news_semiconductor_200_300_semicondutor.csv.csv',\n",
       " 'labeled_news_semiconductor_300_400_semicondutor.csv.csv',\n",
       " 'labeled_news_semiconductor_400_500_semicondutor.csv.csv',\n",
       " 'labeled_news_semiconductor_500_600_semicondutor.csv.csv',\n",
       " 'labeled_news_semiconductor_600_700_semicondutor.csv.csv',\n",
       " 'labeled_news_semiconductor_700_end_semicondutor.csv.csv',\n",
       " 'labeled_news_ship_0_100_ship_building.csv.csv',\n",
       " 'labeled_news_ship_200_300_ship_building.csv.csv',\n",
       " 'labeled_news_ship_300_400_ship_building.csv.csv',\n",
       " 'labeled_news_ship_400_500_ship_building.csv.csv',\n",
       " 'labeled_news_ship_500_600_ship_building.csv.csv',\n",
       " 'labeled_news_ship_600_700_ship_building.csv.csv',\n",
       " 'labeled_news_ship_700_end_ship_building.csv.csv',\n",
       " 'labeled_news_steel_0_100_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_steel_100_200_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_steel_200_300_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_steel_300_400_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_steel_400_500_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_steel_500_600_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_steel_600_700_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_steel_700_end_Steel_manufacturing.csv.csv',\n",
       " 'labeled_news_vh_0_100_Vehicle.csv.csv',\n",
       " 'labeled_news_vh_100_200_Vehicle.csv.csv',\n",
       " 'labeled_news_vh_200_300_Vehicle.csv.csv',\n",
       " 'labeled_news_vh_300_400_Vehicle.csv.csv',\n",
       " 'labeled_news_vh_400_500_Vehicle.csv.csv',\n",
       " 'labeled_news_vh_500_600_Vehicle.csv.csv',\n",
       " 'labeled_news_vh_600_700_Vehicle.csv.csv',\n",
       " 'labeled_news_vh_700_end_Vehicle.csv.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 리스팅\n",
    "import os\n",
    "# csv파일 경로 리스팅 \n",
    "data_lis = os.listdir('./')\n",
    "data_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7866ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복문 이용해서 데이터 합치기 \n",
    "# csv파일 여러개 읽어와서 합치기 \n",
    "df_cnbc = pd.DataFrame()\n",
    "\n",
    "for files in data_lis:\n",
    "    # advertisement 빼고 합치기 \n",
    "    df = pd.read_csv(files,index_col=0)\n",
    "    df_cnbc = pd.concat([df_cnbc,df])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3696c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cnbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e8a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11421d02",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-09-09T04:06:00+0000</td>\n",
       "      <td>['  Bright colors, funky textures and personal...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-09-09T12:34:19+0000</td>\n",
       "      <td>['  You already can invest your retirement mon...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2013-09-09T20:50:18+0000</td>\n",
       "      <td>['  The European automotive market has come un...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-09-10T16:08:23+0000</td>\n",
       "      <td>['  If at first you don’t succeed, order a sec...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2013-09-17T19:10:42+0000</td>\n",
       "      <td>['  Chinese reverse merger companies listed on...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2022-04-22T12:34:04+0000</td>\n",
       "      <td>['American Eagle Outfitters wants to be more l...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022-04-22T19:01:26+0000</td>\n",
       "      <td>['The path to a mega fleet of autonomous vehic...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-04-22T20:20:03+0000</td>\n",
       "      <td>['WASHINGTON — From heavy artillery to tactica...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-04-22T21:15:13+0000</td>\n",
       "      <td>['A new wave of single-stock exchange-traded f...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2022-04-22T21:15:13+0000</td>\n",
       "      <td>['A new wave of single-stock exchange-traded f...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3018 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "23  2013-09-09T04:06:00+0000   \n",
       "15  2013-09-09T12:34:19+0000   \n",
       "60  2013-09-09T20:50:18+0000   \n",
       "5   2013-09-10T16:08:23+0000   \n",
       "50  2013-09-17T19:10:42+0000   \n",
       "..                       ...   \n",
       "51  2022-04-22T12:34:04+0000   \n",
       "29  2022-04-22T19:01:26+0000   \n",
       "62  2022-04-22T20:20:03+0000   \n",
       "19  2022-04-22T21:15:13+0000   \n",
       "67  2022-04-22T21:15:13+0000   \n",
       "\n",
       "                                              content  label  \n",
       "23  ['  Bright colors, funky textures and personal...    102  \n",
       "15  ['  You already can invest your retirement mon...     -1  \n",
       "60  ['  The European automotive market has come un...    104  \n",
       "5   ['  If at first you don’t succeed, order a sec...    104  \n",
       "50  ['  Chinese reverse merger companies listed on...     -1  \n",
       "..                                                ...    ...  \n",
       "51  ['American Eagle Outfitters wants to be more l...    100  \n",
       "29  ['The path to a mega fleet of autonomous vehic...    104  \n",
       "62  ['WASHINGTON — From heavy artillery to tactica...     -1  \n",
       "19  ['A new wave of single-stock exchange-traded f...     -1  \n",
       "67  ['A new wave of single-stock exchange-traded f...     -1  \n",
       "\n",
       "[3018 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463df031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98097e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이랑 피클 저장할 경로로 바꿔주기\n",
    "# ./카테고리분류모델피클 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c70fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\Project4\\카테고리분류모델피클\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\bitcamp\\Project4\\카테고리분류모델피클"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ca2c2",
   "metadata": {},
   "source": [
    "# 토크나이징 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dfd3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "571028b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(docs):\n",
    "    tokenizer = RegexpTokenizer('[\\w]+')\n",
    "    stop_words = stopwords.words('english')\n",
    "    p_stemmer = PorterStemmer()  # 어근 복원 : runs, running, ran => run,  cars => car\n",
    "#     p = re.compile(\"[0-9]+\")\n",
    "#     숫자제거해야됨\n",
    "#     docs = [p.sub(i) for i in docs]\n",
    "    docs = BeautifulSoup(docs, \"html5lib\").get_text()\n",
    "    low = docs.lower()\n",
    "    tokens = tokenizer.tokenize(low)\n",
    "    stopped_tokens = [i for i in tokens if not i in stop_words]\n",
    "    stopped_tokens = [re.sub('[^a-zA-Z0-9]',' ',i) for i in stopped_tokens]\n",
    "    stemmer_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    one_rmv = [w for w in stemmer_tokens if len(w)>1]\n",
    "  \n",
    "    return one_rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a6c4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 적용 \n",
    "df['tokened'] = df['content'].apply(preprocessing)\n",
    "\n",
    "# @@토큰화 하기전 컬럼 보존 @@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "430d4412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>tokened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-09-09T04:06:00+0000</td>\n",
       "      <td>['  Bright colors, funky textures and personal...</td>\n",
       "      <td>102</td>\n",
       "      <td>[bright, color, funki, textur, person, come, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-09-09T12:34:19+0000</td>\n",
       "      <td>['  You already can invest your retirement mon...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[alreadi, invest, retir, money, kid, colleg, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2013-09-09T20:50:18+0000</td>\n",
       "      <td>['  The European automotive market has come un...</td>\n",
       "      <td>104</td>\n",
       "      <td>[european, automot, market, come, unplug, rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-09-10T16:08:23+0000</td>\n",
       "      <td>['  If at first you don’t succeed, order a sec...</td>\n",
       "      <td>104</td>\n",
       "      <td>[first, succeed, order, second, recal, rav4, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2013-09-17T19:10:42+0000</td>\n",
       "      <td>['  Chinese reverse merger companies listed on...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[chines, revers, merger, compani, list, exchan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2022-04-22T12:34:04+0000</td>\n",
       "      <td>['American Eagle Outfitters wants to be more l...</td>\n",
       "      <td>100</td>\n",
       "      <td>[american, eagl, outfitt, want, like, amazon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022-04-22T19:01:26+0000</td>\n",
       "      <td>['The path to a mega fleet of autonomous vehic...</td>\n",
       "      <td>104</td>\n",
       "      <td>[path, mega, fleet, autonom, vehicl, tesla, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-04-22T20:20:03+0000</td>\n",
       "      <td>['WASHINGTON — From heavy artillery to tactica...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[washington, heavi, artilleri, tactic, drone, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-04-22T21:15:13+0000</td>\n",
       "      <td>['A new wave of single-stock exchange-traded f...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[new, wave, singl, stock, exchang, trade, fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2022-04-22T21:15:13+0000</td>\n",
       "      <td>['A new wave of single-stock exchange-traded f...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[new, wave, singl, stock, exchang, trade, fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "23  2013-09-09T04:06:00+0000   \n",
       "15  2013-09-09T12:34:19+0000   \n",
       "60  2013-09-09T20:50:18+0000   \n",
       "5   2013-09-10T16:08:23+0000   \n",
       "50  2013-09-17T19:10:42+0000   \n",
       "..                       ...   \n",
       "51  2022-04-22T12:34:04+0000   \n",
       "29  2022-04-22T19:01:26+0000   \n",
       "62  2022-04-22T20:20:03+0000   \n",
       "19  2022-04-22T21:15:13+0000   \n",
       "67  2022-04-22T21:15:13+0000   \n",
       "\n",
       "                                              content  label  \\\n",
       "23  ['  Bright colors, funky textures and personal...    102   \n",
       "15  ['  You already can invest your retirement mon...     -1   \n",
       "60  ['  The European automotive market has come un...    104   \n",
       "5   ['  If at first you don’t succeed, order a sec...    104   \n",
       "50  ['  Chinese reverse merger companies listed on...     -1   \n",
       "..                                                ...    ...   \n",
       "51  ['American Eagle Outfitters wants to be more l...    100   \n",
       "29  ['The path to a mega fleet of autonomous vehic...    104   \n",
       "62  ['WASHINGTON — From heavy artillery to tactica...     -1   \n",
       "19  ['A new wave of single-stock exchange-traded f...     -1   \n",
       "67  ['A new wave of single-stock exchange-traded f...     -1   \n",
       "\n",
       "                                              tokened  \n",
       "23  [bright, color, funki, textur, person, come, s...  \n",
       "15  [alreadi, invest, retir, money, kid, colleg, s...  \n",
       "60  [european, automot, market, come, unplug, rece...  \n",
       "5   [first, succeed, order, second, recal, rav4, g...  \n",
       "50  [chines, revers, merger, compani, list, exchan...  \n",
       "..                                                ...  \n",
       "51  [american, eagl, outfitt, want, like, amazon, ...  \n",
       "29  [path, mega, fleet, autonom, vehicl, tesla, co...  \n",
       "62  [washington, heavi, artilleri, tactic, drone, ...  \n",
       "19  [new, wave, singl, stock, exchang, trade, fund...  \n",
       "67  [new, wave, singl, stock, exchang, trade, fund...  \n",
       "\n",
       "[3018 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63160a6",
   "metadata": {},
   "source": [
    "# 전처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db313344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 할 변수 만들어 주기 \n",
    "preprocessed_sentences = df['tokened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "548f5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성.\n",
    "# tokenizer.fit_on_texts(preprocessed_sentences) \n",
    "vocab_size = 10000\n",
    "tokenizer = Tokenizer(num_words = vocab_size + 1) \n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "\n",
    "# 상위 1만개 단어 사용 해서 빈도수 기준으로 단어 집합 생성 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5c0e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_on_texts로 토큰화 한 것을 pickle로 저장 \n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "805a9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle파일이 현재 디렉토리에 저장됨 \n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e58447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 시퀀스 형태로 변환해주기 \n",
    "x = tokenizer.texts_to_sequences(preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b88b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련시킬 할 라벨 지정 \n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90128968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d283bb2b",
   "metadata": {},
   "source": [
    "# 모델 돌리기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8adeab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련시킬 데이터 셋 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "194628b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사최대길이로 패딩해주기 \n",
    "max_len = max([len(l) for l in df['tokened']])\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test,maxlen=max_len)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6345e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 구성\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "num_classes = 21\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim))\n",
    "    model.add(LSTM(hidden_units))\n",
    "    model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90b57c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1      1134\n",
       " 100     554\n",
       " 104     479\n",
       " 1       250\n",
       " 3       168\n",
       " 102     162\n",
       " 12       31\n",
       " 13       28\n",
       " 15       27\n",
       " 17       25\n",
       " 21       21\n",
       " 19       21\n",
       " 20       19\n",
       " 22       18\n",
       " 28       14\n",
       " 24       14\n",
       " 101      13\n",
       " 103      12\n",
       " 32       11\n",
       " 31        9\n",
       " 29        8\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f966ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 105) and (None, 21) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21224/1267657055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 105) and (None, 21) are incompatible\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "# 에포크20때까지 val_acc가 개선되지않으면 스톱 \n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "# 제일 훈련이 잘된것을 현재경로에 저장 \n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=30, callbacks=[es, mc], validation_data=(x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 시각화 \n",
    "epochs = range(1, len(history.history['acc']) + 1)\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "epochs = range(1, len(history.history['acc']) + 1)\n",
    "plt.plot(epochs, history.history['acc'])\n",
    "plt.plot(epochs, history.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81eafa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e44416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1455d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12025e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9856e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f0fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41857ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
